[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lake Erie Wind and Wave Data Visulization",
    "section": "",
    "text": "We can create beautiful websites that describe complex technical analyses in Python using Quarto and deploy them online using GitHub Pages. This combination of tools is a really powerful way to create and share your work. This website is a demo that is meant to be used to create your own Quarto website for the final project in MUSA 550.\nQuarto is a relatively new tool, but is becoming popular quickly. It’s a successor to the Rmarkdown ecosystem that combines functionality into a single tool and also extends its computation power to other languages. Most importantly for us, Quarto supports executing Python code, allowing us to convert Jupyter notebooks to HTML and share them online.\n\n\n\n\n\n\nImportant\n\n\n\nThis template site, including the layout it uses, is just a suggested place to start! For your final project, you’re welcome (and encouraged) to make as many changes as you like to best fit your project."
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Lake Erie Wind and Wave Data Visulization",
    "section": "",
    "text": "We can create beautiful websites that describe complex technical analyses in Python using Quarto and deploy them online using GitHub Pages. This combination of tools is a really powerful way to create and share your work. This website is a demo that is meant to be used to create your own Quarto website for the final project in MUSA 550.\nQuarto is a relatively new tool, but is becoming popular quickly. It’s a successor to the Rmarkdown ecosystem that combines functionality into a single tool and also extends its computation power to other languages. Most importantly for us, Quarto supports executing Python code, allowing us to convert Jupyter notebooks to HTML and share them online.\n\n\n\n\n\n\nImportant\n\n\n\nThis template site, including the layout it uses, is just a suggested place to start! For your final project, you’re welcome (and encouraged) to make as many changes as you like to best fit your project."
  },
  {
    "objectID": "index.html#find-out-more",
    "href": "index.html#find-out-more",
    "title": "Lake Erie Wind and Wave Data Visulization",
    "section": "Find out more",
    "text": "Find out more\nThe code for this repository is hosted on our course’s GitHub page: https://github.com/MUSA-550-Fall-2023/quarto-website-template.\nWe covered the basics of getting started with Quarto and GitHub Pages in week 9. Take a look at the slides for lecture 9A to find out more."
  },
  {
    "objectID": "analysis/4-folium.html",
    "href": "analysis/4-folium.html",
    "title": "Interactive Maps with Folium",
    "section": "",
    "text": "This page is generated from a Jupyter notebook and shows examples of embedding interactive maps produced using Folium."
  },
  {
    "objectID": "analysis/4-folium.html#finding-the-shortest-route",
    "href": "analysis/4-folium.html#finding-the-shortest-route",
    "title": "Interactive Maps with Folium",
    "section": "Finding the shortest route",
    "text": "Finding the shortest route\nThis example finds the shortest route between the Art Musuem and the Liberty Bell using osmnx.\n\nimport osmnx as ox\n\nFirst, identify the lat/lng coordinates for our places of interest. Use osmnx to download the geometries for the Libery Bell and Art Museum.\n\nphilly_tourism = ox.features_from_place(\"Philadelphia, PA\", tags={\"tourism\": True})\n\n\nart_museum = philly_tourism.query(\"name == 'Philadelphia Museum of Art'\").squeeze()\n\nart_museum.geometry\n\n\n\n\n\nliberty_bell = philly_tourism.query(\"name == 'Liberty Bell'\").squeeze()\n\nliberty_bell.geometry\n\n\n\n\nNow, extract the lat and lng coordinates\nFor the Art Museum geometry, we can use the .geometry.centroid attribute to calculate the centroid of the building footprint.\n\nliberty_bell_x = liberty_bell.geometry.x\nliberty_bell_y = liberty_bell.geometry.y\n\n\nart_museum_x = art_museum.geometry.centroid.x\nart_museum_y = art_museum.geometry.centroid.y\n\nNext, use osmnx to download the street graph around Center City.\n\nG_cc = ox.graph_from_address(\n    \"City Hall, Philadelphia, USA\", dist=1500, network_type=\"drive\"\n)\n\nNext, identify the nodes in the graph closest to our points of interest.\n\n# Get the origin node (Liberty Bell)\norig_node = ox.nearest_nodes(G_cc, liberty_bell_x, liberty_bell_y)\n\n# Get the destination node (Art Musuem)\ndest_node = ox.nearest_nodes(G_cc, art_museum_x, art_museum_y)\n\nFind the shortest path, based on the distance of the edges:\n\n# Get the shortest path --&gt; just a list of node IDs\nroute = ox.shortest_path(G_cc, orig_node, dest_node, weight=\"length\")\n\nHow about an interactive version?\nosmnx has a helper function ox.utils_graph.route_to_gdf() to convert a route to a GeoDataFrame of edges.\n\nox.utils_graph.route_to_gdf(G_cc, route, weight=\"length\").explore(\n    tiles=\"cartodb positron\",\n    color=\"red\",\n)\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "analysis/4-folium.html#examining-trash-related-311-requests",
    "href": "analysis/4-folium.html#examining-trash-related-311-requests",
    "title": "Interactive Maps with Folium",
    "section": "Examining Trash-Related 311 Requests",
    "text": "Examining Trash-Related 311 Requests\nFirst, let’s load the dataset from a CSV file and convert to a GeoDataFrame:\n\n\nCode\n# Load the data from a CSV file into a pandas DataFrame\ntrash_requests_df = pd.read_csv(\n    \"https://raw.githubusercontent.com/MUSA-550-Fall-2023/week-4/main/data/trash_311_requests_2020.csv\"\n)\n\n# Remove rows with missing geometry\ntrash_requests_df = trash_requests_df.dropna(subset=[\"lat\", \"lon\"])\n\n\n# Create our GeoDataFrame with geometry column created from lon/lat\ntrash_requests = gpd.GeoDataFrame(\n    trash_requests_df,\n    geometry=gpd.points_from_xy(trash_requests_df[\"lon\"], trash_requests_df[\"lat\"]),\n    crs=\"EPSG:4326\",\n)\n\n\nLoad neighborhoods and do the spatial join to associate a neighborhood with each ticket:\n\n\nCode\n# Load the neighborhoods\nneighborhoods = gpd.read_file(\n    \"https://raw.githubusercontent.com/MUSA-550-Fall-2023/week-4/main/data/zillow_neighborhoods.geojson\"\n)\n\n# Do the spatial join to add the \"ZillowName\" column\nrequests_with_hood = gpd.sjoin(\n    trash_requests,\n    neighborhoods.to_crs(trash_requests.crs),\n    predicate=\"within\",\n)\n\n\nLet’s explore the 311 requests in the Greenwich neighborhood of the city:\n\n# Extract out the point tickets for Greenwich\ngreenwich_tickets = requests_with_hood.query(\"ZillowName == 'Greenwich'\")\n\n\n# Get the neighborhood boundary for Greenwich\ngreenwich_geo = neighborhoods.query(\"ZillowName == 'Greenwich'\")\n\ngreenwich_geo.squeeze().geometry\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuarto has callout blocks that you can use to emphasize content in different ways. This is a “Note” callout block. More info is available on the Quarto documentation.\n\n\nImport the packages we need:\n\nimport folium\nimport xyzservices\n\nCombine the tickets as markers and the neighborhood boundary on the same Folium map:\n\n# Plot the neighborhood boundary\nm = greenwich_geo.explore(\n    style_kwds={\"weight\": 4, \"color\": \"black\", \"fillColor\": \"none\"},\n    name=\"Neighborhood boundary\",\n    tiles=xyzservices.providers.CartoDB.Voyager,\n)\n\n\n# Add the individual tickets as circle markers and style them\ngreenwich_tickets.explore(\n    m=m,  # Add to the existing map!\n    marker_kwds={\"radius\": 7, \"fill\": True, \"color\": \"crimson\"},\n    marker_type=\"circle_marker\", # or 'marker' or 'circle'\n    name=\"Tickets\",\n)\n\n# Hse folium to add layer control\nfolium.LayerControl().add_to(m)\n\nm  # show map\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "analysis/2-static-images.html",
    "href": "analysis/2-static-images.html",
    "title": "Showing static visualizations",
    "section": "",
    "text": "This page is generated from a Jupyter notebook and demonstrates how to generate static visualizations with matplotlib, pandas, and seaborn.\nStart by importing the packages we need:\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nLoad the “Palmer penguins” dataset from week 2:\n# Load data on Palmer penguins\npenguins = pd.read_csv(\"https://raw.githubusercontent.com/MUSA-550-Fall-2023/week-2/main/data/penguins.csv\")\n# Show the first ten rows\npenguins.head(n=10)    \n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007\n\n\n6\nAdelie\nTorgersen\n38.9\n17.8\n181.0\n3625.0\nfemale\n2007\n\n\n7\nAdelie\nTorgersen\n39.2\n19.6\n195.0\n4675.0\nmale\n2007\n\n\n8\nAdelie\nTorgersen\n34.1\n18.1\n193.0\n3475.0\nNaN\n2007\n\n\n9\nAdelie\nTorgersen\n42.0\n20.2\n190.0\n4250.0\nNaN\n2007"
  },
  {
    "objectID": "analysis/2-static-images.html#a-simple-visualization-3-different-ways",
    "href": "analysis/2-static-images.html#a-simple-visualization-3-different-ways",
    "title": "Showing static visualizations",
    "section": "A simple visualization, 3 different ways",
    "text": "A simple visualization, 3 different ways\n\nI want to scatter flipper length vs. bill length, colored by the penguin species\n\n\nUsing matplotlib\n\n# Setup a dict to hold colors for each species\ncolor_map = {\"Adelie\": \"#1f77b4\", \"Gentoo\": \"#ff7f0e\", \"Chinstrap\": \"#D62728\"}\n\n# Initialize the figure \"fig\" and axes \"ax\"\nfig, ax = plt.subplots(figsize=(10, 6))\n\n# Group the data frame by species and loop over each group\n# NOTE: \"group\" will be the dataframe holding the data for \"species\"\nfor species, group_df in penguins.groupby(\"species\"):\n\n    # Plot flipper length vs bill length for this group\n    # Note: we are adding this plot to the existing \"ax\" object\n    ax.scatter(\n        group_df[\"flipper_length_mm\"],\n        group_df[\"bill_length_mm\"],\n        marker=\"o\",\n        label=species,\n        color=color_map[species],\n        alpha=0.75,\n        zorder=10\n    )\n\n# Plotting is done...format the axes!\n\n## Add a legend to the axes\nax.legend(loc=\"best\")\n\n## Add x-axis and y-axis labels\nax.set_xlabel(\"Flipper Length (mm)\")\nax.set_ylabel(\"Bill Length (mm)\")\n\n## Add the grid of lines\nax.grid(True);\n\n\n\n\n\n\nHow about in pandas?\nDataFrames have a built-in “plot” function that can make all of the basic type of matplotlib plots!\nFirst, we need to add a new “color” column specifying the color to use for each species type.\nUse the pd.replace() function: it use a dict to replace values in a DataFrame column.\n\n# Calculate a list of colors\ncolor_map = {\"Adelie\": \"#1f77b4\", \"Gentoo\": \"#ff7f0e\", \"Chinstrap\": \"#D62728\"}\n\n# Map species name to color \npenguins[\"color\"] = penguins[\"species\"].replace(color_map)\n\npenguins.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\ncolor\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n#1f77b4\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n#1f77b4\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n#1f77b4\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n#1f77b4\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n#1f77b4\n\n\n\n\n\n\n\nNow plot!\n\n# Same as before: Start by initializing the figure and axes\nfig, myAxes = plt.subplots(figsize=(10, 6))\n\n# Scatter plot two columns, colored by third\n# Use the built-in pandas plot.scatter function\npenguins.plot.scatter(\n    x=\"flipper_length_mm\",\n    y=\"bill_length_mm\",\n    c=\"color\",\n    alpha=0.75,\n    ax=myAxes, # IMPORTANT: Make sure to plot on the axes object we created already!\n    zorder=10\n)\n\n# Format the axes finally\nmyAxes.set_xlabel(\"Flipper Length (mm)\")\nmyAxes.set_ylabel(\"Bill Length (mm)\")\nmyAxes.grid(True);\n\n\n\n\nNote: no easy way to get legend added to the plot in this case…\n\n\nSeaborn: statistical data visualization\nSeaborn is designed to plot two columns colored by a third column…\n\n# Initialize the figure and axes\nfig, ax = plt.subplots(figsize=(10, 6))\n\n# style keywords as dict\ncolor_map = {\"Adelie\": \"#1f77b4\", \"Gentoo\": \"#ff7f0e\", \"Chinstrap\": \"#D62728\"}\nstyle = dict(palette=color_map, s=60, edgecolor=\"none\", alpha=0.75, zorder=10)\n\n# use the scatterplot() function\nsns.scatterplot(\n    x=\"flipper_length_mm\",  # the x column\n    y=\"bill_length_mm\",  # the y column\n    hue=\"species\",  # the third dimension (color)\n    data=penguins,  # pass in the data\n    ax=ax,  # plot on the axes object we made\n    **style  # add our style keywords\n)\n\n# Format with matplotlib commands\nax.set_xlabel(\"Flipper Length (mm)\")\nax.set_ylabel(\"Bill Length (mm)\")\nax.grid(True)\nax.legend(loc=\"best\");"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "On this about page, you might want to add more information about yourself, the project, or course. Any helpful context could go here!\nMy name is Nick Hand, the instructor for the course. You can find more information about me on my personal website.\nThis site is an example site showing how to use Quarto for the final project for MUSA 550, during fall 2023.\nAdipisicing proident minim non non dolor quis. Pariatur in ipsum aliquip magna. Qui ad aliqua nulla excepteur dolor nostrud quis nisi. Occaecat proident eiusmod in cupidatat. Elit qui laboris sit aliquip proident dolore. Officia commodo commodo in eiusmod aliqua sint cupidatat consectetur aliqua sint reprehenderit.\nOccaecat incididunt esse et elit adipisicing sit est cupidatat consequat. Incididunt exercitation amet dolor non sit anim veniam veniam sint velit. Labore irure reprehenderit ut esse. Minim quis commodo nisi voluptate."
  },
  {
    "objectID": "analysis/1-python-code-blocks.html",
    "href": "analysis/1-python-code-blocks.html",
    "title": "Python code blocks",
    "section": "",
    "text": "This is an example from the Quarto documentation that shows how to mix executable Python code blocks into a markdown file in a “Quarto markdown” .qmd file.\nFor a demonstration of a line plot on a polar axis, see Figure 1.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\nFigure 1: A line plot on a polar axis"
  },
  {
    "objectID": "analysis/3-altair-hvplot.html",
    "href": "analysis/3-altair-hvplot.html",
    "title": "Altair and Hvplot Charts",
    "section": "",
    "text": "This page is generated from a Jupyter notebook and shows examples of embedding interactive charts produced using Altair and hvPlot."
  },
  {
    "objectID": "analysis/3-altair-hvplot.html#example-measles-incidence-in-altair",
    "href": "analysis/3-altair-hvplot.html#example-measles-incidence-in-altair",
    "title": "Altair and Hvplot Charts",
    "section": "Example: Measles Incidence in Altair",
    "text": "Example: Measles Incidence in Altair\nFirst, let’s load the data for measles incidence in wide format:\n\n\nCode\nurl = \"https://raw.githubusercontent.com/MUSA-550-Fall-2023/week-2/main/data/measles_incidence.csv\"\ndata = pd.read_csv(url, skiprows=2, na_values=\"-\")\n\n\n\n\n\n\n\n\n\n\n\nYEAR\nWEEK\nALABAMA\nALASKA\nARIZONA\nARKANSAS\nCALIFORNIA\nCOLORADO\nCONNECTICUT\nDELAWARE\n...\nSOUTH DAKOTA\nTENNESSEE\nTEXAS\nUTAH\nVERMONT\nVIRGINIA\nWASHINGTON\nWEST VIRGINIA\nWISCONSIN\nWYOMING\n\n\n\n\n0\n1928\n1\n3.67\nNaN\n1.90\n4.11\n1.38\n8.38\n4.50\n8.58\n...\n5.69\n22.03\n1.18\n0.4\n0.28\nNaN\n14.83\n3.36\n1.54\n0.91\n\n\n1\n1928\n2\n6.25\nNaN\n6.40\n9.91\n1.80\n6.02\n9.00\n7.30\n...\n6.57\n16.96\n0.63\nNaN\n0.56\nNaN\n17.34\n4.19\n0.96\nNaN\n\n\n2\n1928\n3\n7.95\nNaN\n4.50\n11.15\n1.31\n2.86\n8.81\n15.88\n...\n2.04\n24.66\n0.62\n0.2\n1.12\nNaN\n15.67\n4.19\n4.79\n1.36\n\n\n3\n1928\n4\n12.58\nNaN\n1.90\n13.75\n1.87\n13.71\n10.40\n4.29\n...\n2.19\n18.86\n0.37\n0.2\n6.70\nNaN\n12.77\n4.66\n1.64\n3.64\n\n\n4\n1928\n5\n8.03\nNaN\n0.47\n20.79\n2.38\n5.13\n16.80\n5.58\n...\n3.94\n20.05\n1.57\n0.4\n6.70\nNaN\n18.83\n7.37\n2.91\n0.91\n\n\n\n\n5 rows × 53 columns\n\n\n\nThen, use the pandas.melt() function to convert it to tidy format:\n\n\nCode\nannual = data.drop(\"WEEK\", axis=1)\nmeasles = annual.groupby(\"YEAR\").sum().reset_index()\nmeasles = measles.melt(id_vars=\"YEAR\", var_name=\"state\", value_name=\"incidence\")\n\n\n\n\n\n\n\n\n\n\n\nYEAR\nstate\nincidence\n\n\n\n\n0\n1928\nALABAMA\n334.99\n\n\n1\n1929\nALABAMA\n111.93\n\n\n2\n1930\nALABAMA\n157.00\n\n\n3\n1931\nALABAMA\n337.29\n\n\n4\n1932\nALABAMA\n10.21\n\n\n\n\n\n\n\nFinally, load altair:\n\nimport altair as alt\n\nAnd generate our final data viz:\n\n# use a custom color map\ncolormap = alt.Scale(\n    domain=[0, 100, 200, 300, 1000, 3000],\n    range=[\n        \"#F0F8FF\",\n        \"cornflowerblue\",\n        \"mediumseagreen\",\n        \"#FFEE00\",\n        \"darkorange\",\n        \"firebrick\",\n    ],\n    type=\"sqrt\",\n)\n\n# Vertical line for vaccination year\nthreshold = pd.DataFrame([{\"threshold\": 1963}])\n\n# plot YEAR vs state, colored by incidence\nchart = (\n    alt.Chart(measles)\n    .mark_rect()\n    .encode(\n        x=alt.X(\"YEAR:O\", axis=alt.Axis(title=None, ticks=False)),\n        y=alt.Y(\"state:N\", axis=alt.Axis(title=None, ticks=False)),\n        color=alt.Color(\"incidence:Q\", sort=\"ascending\", scale=colormap, legend=None),\n        tooltip=[\"state\", \"YEAR\", \"incidence\"],\n    )\n    .properties(width=650, height=500)\n)\n\nrule = alt.Chart(threshold).mark_rule(strokeWidth=4).encode(x=\"threshold:O\")\n\nout = chart + rule\nout"
  },
  {
    "objectID": "analysis/3-altair-hvplot.html#example-measles-incidence-in-hvplot",
    "href": "analysis/3-altair-hvplot.html#example-measles-incidence-in-hvplot",
    "title": "Altair and Hvplot Charts",
    "section": "Example: Measles Incidence in hvplot",
    "text": "Example: Measles Incidence in hvplot\n\n\n\n\n\n\n\n\n\n\n\n\nGenerate the same data viz in hvplot:\n\n# Make the heatmap with hvplot\nheatmap = measles.hvplot.heatmap(\n    x=\"YEAR\",\n    y=\"state\",\n    C=\"incidence\", # color each square by the incidence\n    reduce_function=np.sum, # sum the incidence for each state/year\n    frame_height=450,\n    frame_width=600,\n    flip_yaxis=True,\n    rot=90,\n    colorbar=False,\n    cmap=\"viridis\",\n    xlabel=\"\",\n    ylabel=\"\",\n)\n\n# Some additional formatting using holoviews \n# For more info: http://holoviews.org/user_guide/Customizing_Plots.html\nheatmap = heatmap.redim(state=\"State\", YEAR=\"Year\")\nheatmap = heatmap.opts(fontsize={\"xticks\": 0, \"yticks\": 6}, toolbar=\"above\")\nheatmap"
  },
  {
    "objectID": "analysis/index.html",
    "href": "analysis/index.html",
    "title": "Analysis",
    "section": "",
    "text": "Analysis\nThis section includes examples of technical analysis done using Jupyter notebooks. Each sub-section highlights different types of analyses and visualizations. In particular, it highlights that we can easily publish interactive visualizations produced with packages such as hvPlot, altair, or Folium, without losing any of the interactive features.\nOn this page, you might want to share more introductory or background information about the analyses to help guide the reader."
  },
  {
    "objectID": "analysis/wind-data-visulize.html",
    "href": "analysis/wind-data-visulize.html",
    "title": "Wind Data Visualization",
    "section": "",
    "text": "Wind Data Source: ERA5 climate data from Climate Data Store\nThe wind data in this project comes from the ‘ERA5 monthly averaged data on single levels from 1940 to present’ dataset, specifically the 10m u-component of wind and 10m v-component of wind.\nThe time period will be 2022 yearly data, and the area of interest will be Lake Erie.\n\nimport numpy as np\nimport pandas as pd\nimport geopandas as gpd\nimport xarray as xr\nfrom matplotlib import pyplot as plt\nimport datashader as ds\nimport imageio\n\n\nStep 1: Read the .nc file downloaded from the ERA5 website and calculate wind strength\nRead .nc file downloaded from Climate Data Store\n\nwindnc = xr.open_dataset('./data/ERA5climate4.nc')  \n\nExtract latitude and longitude data of each point\n\nlat = windnc.latitude\nlon = windnc.longitude\n\nExtract wind uv data\n\nwind_u = windnc.u10\nwind_v = windnc.v10\n\nCalculate wind strength (m/s) based on wind uv data\n\nWS = np.sqrt(wind_u**2 + wind_v**2)\n\n\n\nStep 2: plot wind field map for each month in 2022 and generate a gif\nRead the Lake Erie shapefile extracted from USGS National Hydrography Dataset and change it to the same projection as wind data (CRS 4326)\n\nlake = gpd.read_file(\"./data/LakeErie\")\n\n\nlake4326 = lake.to_crs(epsg=4326)\n\nDefine a function to collect the plot for each month\nThe plot contains three components: the wind field map (array array), the wind strength map (color), and Lake Erie location (shape).\nThe wind field map is generated through vector calculation.\nThe wind strength map is generated through each point’s relationship to its neighbors.\n\n# Have a list of month names for the function to use\nmonthlist = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n\n\ndef plot_wind_by_month(month):\n    \"\"\"Plot wind field map for each month in 2022\"\"\"\n    fig, ax = plt.subplots(figsize=(10,6))\n\n    # Wind strength map\n    cf = plt.contourf(lon,lat,WS[month,:,:], levels=15, cmap='rainbow', alpha=0.8)\n    \n    # lake Erie shape\n    lake4326.plot(ax=plt.gca(), edgecolor='#25408F', facecolor='none', linewidth=0.5)\n    \n    # Wind field map with labels\n    Q = plt.quiver(lon,lat,wind_u[month,:,:],wind_v[month,:,:], scale_units='xy', scale=4, width=0.0014, color='white')\n    qk = plt.quiverkey(Q, \n                  1, 1.02, \n                   1,str(1)+' m/s',   \n                   labelpos='E',                \n                   coordinates='axes',\n                   color='black'\n                   )\n\n    # style adjustments\n    cb = plt.colorbar(cf, fraction=0.0235, pad=0.03)\n    cb.set_label('m/s',  fontsize=11)\n    plt.xlabel('Longitude')\n    plt.ylabel('Latitude')\n    plt.title(f'Wind Field Map of {monthlist[month]}')\n\n    # prepare for imageio\n    fig.canvas.draw()\n    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype=\"uint8\")\n    image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n    \n    return image\n\nUse the function above to see the wind strenghth for each month and generate a gif for the wind visualization\n\nimgs = []\nfor month in range(12):\n    img = plot_wind_by_month(month)\n    imgs.append(img)\n\n# Combing the images for each month into a single GIF\nimageio.mimsave(\"wind-field.gif\", imgs, duration=1000)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe gif generated above does not have infinite loop, so Onlinegiftools can help change that property\nThe final visualization is below:\n\n\n\nStep 3: Analyze the result\nResult:\nThe gif works smoothly and clearly displays the wind change within 2022. The prevailing wind for Lake Erie is southwest, which is because of the typical seiche pattern. Because all the vectors of the wind field map are on the same scale, we can see that Lake Erie has severely larger wind in the winter.\nEvent:\nThe dominant southwest wind usually causes much damage to residents near the coastline in winter. Historic winter storms dumped 50 inches of snow per year in the region. In December 2022, blizzards and seiche killed 50 people, including 27 in Buffalo, and created a catastrophic blanket of ice across the city.\nCompare:\nThe gif result can reflect the event above. In November and December, the wind field arrays are much longer than the arrays in other months."
  },
  {
    "objectID": "analysis/web-scraping-wave-data.html",
    "href": "analysis/web-scraping-wave-data.html",
    "title": "Web Scraping of Wave Height Data from Buoys",
    "section": "",
    "text": "Wave Data Source: WIS Data Portal\nThe wave data in this project comes from the buoys’ on Lake Erie. The data gathering process uses web scraping because there are too many bouys to be downloaded manully.\nThe time period will be 2022 yearly data, and the area of interest is the part of Lake Erie in New York State’s boundary (highlighted in yellow).\n\n\nimport requests\n# Import the webdriver from selenium\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\n\n\nfrom time import sleep\n\n\nStep 1: Set up driver\n\ndriver = webdriver.Chrome()\n\nThis website takes a long time to load, so here we will stop for 10 seconds before continue the following steps\n\nurl = \"https://wisportal.erdc.dren.mil/#\"\ndriver.get(url)\nsleep(10)\n\n\n\nStep 2: Add wave height data of each buoy to an export group online\nBecause the buoys buttons on the website are markers generated by leaflet, the ID selectors associated with each marker are in a random numbering. Firstly, we need to have a list of all the buoy ID in the prefered sequence, which is from the south to the north.\n\n\n\n\n\n\nImportant\n\n\n\nBecause of the randomness associated with the leaflet marker ID, some of them may not be the same ID for each session (although most of them will stay the same). The ID may be slightly varied from the list below. Make sure to recheck them before reusing them.\n\n\n\nmarker_list = ['#map-view &gt; div.leaflet-pane.leaflet-map-pane &gt; div.leaflet-pane.leaflet-marker-pane &gt; img:nth-child(3014)',\n'#map-view &gt; div.leaflet-pane.leaflet-map-pane &gt; div.leaflet-pane.leaflet-marker-pane &gt; img:nth-child(2281)',\n'#map-view &gt; div.leaflet-pane.leaflet-map-pane &gt; div.leaflet-pane.leaflet-marker-pane &gt; img:nth-child(2241)',\n'#map-view &gt; div.leaflet-pane.leaflet-map-pane &gt; div.leaflet-pane.leaflet-marker-pane &gt; img:nth-child(2278)',\n'#map-view &gt; div.leaflet-pane.leaflet-map-pane &gt; div.leaflet-pane.leaflet-marker-pane &gt; img:nth-child(2275)',\n'#map-view &gt; div.leaflet-pane.leaflet-map-pane &gt; div.leaflet-pane.leaflet-marker-pane &gt; img:nth-child(2547)',\n'#map-view &gt; div.leaflet-pane.leaflet-map-pane &gt; div.leaflet-pane.leaflet-marker-pane &gt; img:nth-child(2886)',\n'#map-view &gt; div.leaflet-pane.leaflet-map-pane &gt; div.leaflet-pane.leaflet-marker-pane &gt; img:nth-child(2545)',\n'#map-view &gt; div.leaflet-pane.leaflet-map-pane &gt; div.leaflet-pane.leaflet-marker-pane &gt; img:nth-child(2272)',\n'#map-view &gt; div.leaflet-pane.leaflet-map-pane &gt; div.leaflet-pane.leaflet-marker-pane &gt; img:nth-child(2881)',\n'#map-view &gt; div.leaflet-pane.leaflet-map-pane &gt; div.leaflet-pane.leaflet-marker-pane &gt; img:nth-child(3009)',\n'#map-view &gt; div.leaflet-pane.leaflet-map-pane &gt; div.leaflet-pane.leaflet-marker-pane &gt; img:nth-child(2269)',\n'#map-view &gt; div.leaflet-pane.leaflet-map-pane &gt; div.leaflet-pane.leaflet-marker-pane &gt; img:nth-child(2266)',\n'#map-view &gt; div.leaflet-pane.leaflet-map-pane &gt; div.leaflet-pane.leaflet-marker-pane &gt; img:nth-child(3012)',\n'#map-view &gt; div.leaflet-pane.leaflet-map-pane &gt; div.leaflet-pane.leaflet-marker-pane &gt; img:nth-child(3010)',\n'#map-view &gt; div.leaflet-pane.leaflet-map-pane &gt; div.leaflet-pane.leaflet-marker-pane &gt; img:nth-child(2263)',\n'#map-view &gt; div.leaflet-pane.leaflet-map-pane &gt; div.leaflet-pane.leaflet-marker-pane &gt; img:nth-child(2876)',\n'#map-view &gt; div.leaflet-pane.leaflet-map-pane &gt; div.leaflet-pane.leaflet-marker-pane &gt; img:nth-child(2872)',\n'#map-view &gt; div.leaflet-pane.leaflet-map-pane &gt; div.leaflet-pane.leaflet-marker-pane &gt; img:nth-child(2543)',\n'#map-view &gt; div.leaflet-pane.leaflet-map-pane &gt; div.leaflet-pane.leaflet-marker-pane &gt; img:nth-child(3006)',\n'#map-view &gt; div.leaflet-pane.leaflet-map-pane &gt; div.leaflet-pane.leaflet-marker-pane &gt; img:nth-child(2867)',\n'#map-view &gt; div.leaflet-pane.leaflet-map-pane &gt; div.leaflet-pane.leaflet-marker-pane &gt; img:nth-child(3007)',\n'#map-view &gt; div.leaflet-pane.leaflet-map-pane &gt; div.leaflet-pane.leaflet-marker-pane &gt; img:nth-child(2541)',\n'#map-view &gt; div.leaflet-pane.leaflet-map-pane &gt; div.leaflet-pane.leaflet-marker-pane &gt; img:nth-child(2384)']\n\nSince there are a lot of buoys, a function can help us handle the scraping process of each individual\n\ndef add_each_marker_to_export_group(marker_selector):\n    \"\"\"handle the scraping process of each marker\"\"\"\n    # click marker\n    buoy_input = driver.find_element(By.CSS_SELECTOR, marker_selector)\n    buoy_input.click()\n    sleep(1)\n    \n    # click general export button\n    general_export_selector = \"#generic_export\"\n    general_export_input = driver.find_element(By.CSS_SELECTOR, general_export_selector)\n    general_export_input.click()\n    sleep(1)\n    \n    # check wave height checkbox\n    waveheight_selector = \"#check-waveHs\"\n    waveheight_check = driver.find_element(By.CSS_SELECTOR, waveheight_selector)\n    waveheight_check.click()\n    sleep(1)\n    \n    # add to export group\n    add_to_export_group_selector = \"#ep-export-button\"\n    add_to_export_group_button = driver.find_element(By.CSS_SELECTOR, add_to_export_group_selector)\n    add_to_export_group_button.click()\n    sleep(1)\n\nApply the above function to each marker in the list\n\nfor i in range(len(marker_list)):\n    marker_selector = marker_list[i]\n    add_each_marker_to_export_group(marker_selector)\n    sleep(1)\n    \n\n\n\nStep 3: Download the export group\nAfter adding all the buoy data we need, we will download the export group summary, which will be a zip file\n\n# Go to the export group summary page\nexport_group_selector = \"#export-summary\"\nexport_group_button = driver.find_element(By.CSS_SELECTOR, export_group_selector)\nexport_group_button.click()\n\n# Download the data we need\ndownload_selector = \"#ep-download-all-button\"\ndownload_button = driver.find_element(By.CSS_SELECTOR, download_selector)\ndownload_button.click()\nsleep(10)\n\n\n\nStep 4: Close Driver\n\ndriver.close()"
  }
]